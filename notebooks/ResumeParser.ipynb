{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Loads variables from .env\n",
        "\n",
        "api_key = os.getenv(\"TOGETHER_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiZMB8Qfi8yj",
        "outputId": "d2b735a5-1d7d-43a3-822f-2325ae260c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdfplumber\n",
            "  Using cached pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
            "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
            "  Using cached pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfplumber) (10.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.3.2)\n",
            "Collecting cryptography>=36.0.0 (from pdfminer.six==20250327->pdfplumber)\n",
            "  Using cached cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
            "Collecting cffi>=1.12 (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber)\n",
            "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
            "Collecting pycparser (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Using cached pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
            "Using cached pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
            "Using cached pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
            "Using cached cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
            "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Installing collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
            "Successfully installed cffi-1.17.1 cryptography-44.0.2 pdfminer.six-20250327 pdfplumber-0.11.6 pycparser-2.22 pypdfium2-4.30.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\2310s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\2310s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\2310s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting together\n",
            "  Using cached together-1.5.5-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.9.3 (from together)\n",
            "  Using cached aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.7 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from together) (8.1.7)\n",
            "Collecting eval-type-backport<0.3.0,>=0.1.3 (from together)\n",
            "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from together) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from together) (1.26.4)\n",
            "Collecting pillow<12.0.0,>=11.1.0 (from together)\n",
            "  Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from together) (17.0.0)\n",
            "Collecting pydantic<3.0.0,>=2.6.3 (from together)\n",
            "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from together) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.8.1 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from together) (13.8.1)\n",
            "Collecting tabulate<0.10.0,>=0.9.0 (from together)\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from together) (4.66.5)\n",
            "Collecting typer<0.16,>=0.9 (from together)\n",
            "  Using cached typer-0.15.3-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.9.3->together)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.9.3->together)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.3->together)\n",
            "  Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.9.3->together)\n",
            "  Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.9.3->together)\n",
            "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.9.3->together)\n",
            "  Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\2310s\\appdata\\roaming\\python\\python312\\site-packages (from click<9.0.0,>=8.1.7->together) (0.4.6)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.6.3->together)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.6.3->together)\n",
            "  Using cached pydantic_core-2.33.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.6.3->together)\n",
            "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.31.0->together) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\2310s\\appdata\\roaming\\python\\python312\\site-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
            "Collecting shellingham>=1.3.0 (from typer<0.16,>=0.9->together)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\2310s\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
            "Using cached together-1.5.5-py3-none-any.whl (87 kB)\n",
            "Using cached aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
            "Using cached eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
            "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
            "Using cached pydantic_core-2.33.1-cp312-cp312-win_amd64.whl (2.0 MB)\n",
            "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Using cached typer-0.15.3-py3-none-any.whl (45 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
            "Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
            "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
            "Installing collected packages: typing-inspection, tabulate, shellingham, pydantic-core, propcache, pillow, multidict, frozenlist, eval-type-backport, annotated-types, aiohappyeyeballs, yarl, pydantic, aiosignal, typer, aiohttp, together\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 10.4.0\n",
            "    Uninstalling pillow-10.4.0:\n",
            "      Successfully uninstalled pillow-10.4.0\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 eval-type-backport-0.2.2 frozenlist-1.6.0 multidict-6.4.3 pillow-11.2.1 propcache-0.3.1 pydantic-2.11.3 pydantic-core-2.33.1 shellingham-1.5.4 tabulate-0.9.0 together-1.5.5 typer-0.15.3 typing-inspection-0.4.0 yarl-1.20.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\2310s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\2310s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\2310s\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "easyocr 1.7.2 requires torch, which is not installed.\n",
            "easyocr 1.7.2 requires torchvision>=0.5, which is not installed.\n",
            "streamlit 1.34.0 requires pillow<11,>=7.1.0, but you have pillow 11.2.1 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber\n",
        "!pip install together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wblqY31yjLpN",
        "outputId": "2246be8f-dd89-4141-c8d3-de9177191eba"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pdfplumber'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdfplumber\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_pdf_text\u001b[39m(pdf_path):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m pdfplumber\u001b[38;5;241m.\u001b[39mopen(pdf_path) \u001b[38;5;28;01mas\u001b[39;00m pdf:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfplumber'"
          ]
        }
      ],
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_pdf_text(pdf_path):\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        full_text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            full_text += page.extract_text()\n",
        "    return full_text\n",
        "\n",
        "# Test the extraction\n",
        "pdf_path = \"/content/SathishKumar_Data Scientist.pdf\"\n",
        "pdf_text = extract_pdf_text(pdf_path)\n",
        "print(pdf_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoUAuLDOk5k9",
        "outputId": "67c7c223-0d61-4dd8-a144-b15e1a1edb75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"ns1SFj8-3NKUce-937d4b71f9c51d64\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1745913930,\n",
            "  \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
            "  \"prompt\": [],\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"seed\": 15242759706418150000,\n",
            "      \"logprobs\": null,\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \" {\\n  \\\"name\\\": \\\"SATHISH KUMAR\\\",\\n  \\\"email\\\": \\\"2310sathishkumarsk@gmail.com\\\",\\n  \\\"phone\\\": \\\"+91 8825743005\\\",\\n  \\\"linkedin\\\": \\\"null\\\",\\n  \\\"skills\\\": [\\n    \\\"Python\\\",\\n    \\\"NumPy\\\",\\n    \\\"Pandas\\\",\\n    \\\"SQL\\\",\\n    \\\"MySQL\\\",\\n    \\\"Machine Learning\\\",\\n    \\\"PyTorch\\\",\\n    \\\"Scikit-learn\\\",\\n    \\\"Power BI\\\",\\n    \\\"Data Analysis\\\",\\n    \\\"Natural Language Processing(NLP)\\\",\\n    \\\"Data Preprocessing\\\",\\n    \\\"Feature Engineering\\\"\\n  ],\\n  \\\"education\\\": [\\n    {\\n      \\\"degree\\\": \\\"Bachelor of Business Administration\\\",\\n      \\\"institution\\\": \\\"Vidyasagar College of Arts and Science Udumalpet, India\\\",\\n      \\\"year\\\": \\\"2019 \\u2013 2022\\\"\\n    },\\n    {\\n      \\\"degree\\\": \\\"Advanced Programming Professional & Master Data Science\\\",\\n      \\\"institution\\\": \\\"IIT-M GUVI Chennai, India\\\",\\n      \\\"year\\\": \\\"2023 \\u2013 2024\\\"\\n    }\\n  ],\\n  \\\"experience\\\": [\\n    {\\n      \\\"company\\\": \\\"null\\\",\\n      \\\"title\\\": \\\"Data Science Specialist Intern\\\",\\n      \\\"duration\\\": \\\"null\\\",\\n      \\\"description\\\": \\\"Eager to contribute to GUVI\\u2019s mission of accessible vernacular tech learning.\\\"\\n    }\\n  ],\\n  \\\"certifications\\\": [\\n    \\\"Python for Data Science - IBM\\\",\\n    \\\"Data Analytics Essentials - CISCO\\\",\\n    \\\"Microsoft Power BI - Guvi\\\"\\n  ],\\n  \\\"projects\\\": [\\n    {\\n      \\\"title\\\": \\\"Telecom Churn Prediction and Analysis\\\",\\n      \\\"description\\\": \\\"Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention. Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention efforts. Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on Render for real-time predictions. Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\\\"\\n    },\\n    {\\n      \\\"title\\\": \\\"Loan Approval Predictor\\\",\\n      \\\"description\\\": \\\"Developed a machine learning model to predict loan approval, optimizing the lending decision-making process. Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model evaluation. Analyzed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable, and trained an XGBoost model, achieving 99% accuracy.\\\"\\n    },\\n    {\\n      \\\"title\\\": \\\"British Airways Data Science Job Simulation\\\",\\n      \\\"description\\\": \\\"Scraped customer review data from the British Airways website and analyzed sentiment using SentimentIntensityAnalyzer, visualizing key trends with word clouds. Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after hyperparameter tuning. Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence booking decisions. Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\\\"\\n    }\\n  ],\\n  \\\"confidence_scores\\\": {\\n    \\\"name\\\": 1.0,\\n    \\\"email\\\": 1.0,\\n    \\\"phone\\\": 1.0,\\n    \\\"linkedin\\\": 0.0,\\n    \\\"skills\\\": 1.0,\\n    \\\"education\\\": 1.0,\\n    \\\"experience\\\": 0.5,\\n    \\\"certifications\\\": 1.0,\\n    \\\"projects\\\": 1.0\\n  }\\n}\",\n",
            "        \"tool_calls\": []\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1466,\n",
            "    \"completion_tokens\": 915,\n",
            "    \"total_tokens\": 2381\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "Result:\n",
            "\n",
            " {\n",
            "  \"name\": \"SATHISH KUMAR\",\n",
            "  \"email\": \"2310sathishkumarsk@gmail.com\",\n",
            "  \"phone\": \"+91 8825743005\",\n",
            "  \"linkedin\": \"null\",\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"NumPy\",\n",
            "    \"Pandas\",\n",
            "    \"SQL\",\n",
            "    \"MySQL\",\n",
            "    \"Machine Learning\",\n",
            "    \"PyTorch\",\n",
            "    \"Scikit-learn\",\n",
            "    \"Power BI\",\n",
            "    \"Data Analysis\",\n",
            "    \"Natural Language Processing(NLP)\",\n",
            "    \"Data Preprocessing\",\n",
            "    \"Feature Engineering\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Bachelor of Business Administration\",\n",
            "      \"institution\": \"Vidyasagar College of Arts and Science Udumalpet, India\",\n",
            "      \"year\": \"2019 – 2022\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"Advanced Programming Professional & Master Data Science\",\n",
            "      \"institution\": \"IIT-M GUVI Chennai, India\",\n",
            "      \"year\": \"2023 – 2024\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"null\",\n",
            "      \"title\": \"Data Science Specialist Intern\",\n",
            "      \"duration\": \"null\",\n",
            "      \"description\": \"Eager to contribute to GUVI’s mission of accessible vernacular tech learning.\"\n",
            "    }\n",
            "  ],\n",
            "  \"certifications\": [\n",
            "    \"Python for Data Science - IBM\",\n",
            "    \"Data Analytics Essentials - CISCO\",\n",
            "    \"Microsoft Power BI - Guvi\"\n",
            "  ],\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"title\": \"Telecom Churn Prediction and Analysis\",\n",
            "      \"description\": \"Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention. Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention efforts. Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on Render for real-time predictions. Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Loan Approval Predictor\",\n",
            "      \"description\": \"Developed a machine learning model to predict loan approval, optimizing the lending decision-making process. Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model evaluation. Analyzed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable, and trained an XGBoost model, achieving 99% accuracy.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"British Airways Data Science Job Simulation\",\n",
            "      \"description\": \"Scraped customer review data from the British Airways website and analyzed sentiment using SentimentIntensityAnalyzer, visualizing key trends with word clouds. Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after hyperparameter tuning. Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence booking decisions. Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\"\n",
            "    }\n",
            "  ],\n",
            "  \"confidence_scores\": {\n",
            "    \"name\": 1.0,\n",
            "    \"email\": 1.0,\n",
            "    \"phone\": 1.0,\n",
            "    \"linkedin\": 0.0,\n",
            "    \"skills\": 1.0,\n",
            "    \"education\": 1.0,\n",
            "    \"experience\": 0.5,\n",
            "    \"certifications\": 1.0,\n",
            "    \"projects\": 1.0\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pdfplumber\n",
        "\n",
        "\n",
        "# Define prompt\n",
        "prompt = f\"\"\"\n",
        "You are an expert resume parser.\n",
        "\n",
        "Task:\n",
        "Parse the following resume content and extract structured fields. Return the result ONLY in the following strict JSON format:\n",
        "\n",
        "Instructions:\n",
        "- Do not guess. If a field is not explicitly present in the text, set its value to the JSON null value (without quotes).\n",
        "- Read the ENTIRE content carefully, especially the profile/summary and projects section, to extract all relevant skills.\n",
        "- Add skills from projects or summary sections **only if they are not already included** in the skills list.\n",
        "- LinkedIn: Only extract a LinkedIn URL if it is a valid personal LinkedIn profile (e.g., starts with \"https://linkedin.com/in/username\"). If it's just the word \"LinkedIn\", a logo, or a general link (e.g., \"linkedin.com\"), set the field to null.\n",
        "- Work Experience vs. Projects:\n",
        "  - Treat as **work experience** only if BOTH a valid company name and a clear duration (e.g., \"Jan 2020 – Mar 2022\") are present.\n",
        "  - If any of the following are **missing** — company name, duration, or job title — classify it as a **project**.\n",
        "  - Terms like \"Project\", \"Capstone\", \"Intern Project\", \"Practical Experience\", or job simulation **should be treated as projects**, NOT experience.\n",
        "- Extract project title and description from such entries and move them to the \"projects\" section.\n",
        "- Normalize all dates to \"MMM YYYY\" format where possible (e.g., \"Jan 2020\").\n",
        "- Include a confidence score (0.0–1.0) for each field in the `confidence_scores` section.\n",
        "- Return all results ONLY in this strict JSON format:\n",
        "\n",
        "{{\n",
        "  \"name\": \"\",\n",
        "  \"email\": \"\",\n",
        "  \"phone\": \"\",\n",
        "  \"linkedin\": \"\",\n",
        "  \"skills\": [],\n",
        "  \"education\": [\n",
        "    {{\n",
        "      \"degree\": \"\",\n",
        "      \"institution\": \"\",\n",
        "      \"year\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"experience\": [\n",
        "    {{\n",
        "      \"company\": \"\",\n",
        "      \"title\": \"\",\n",
        "      \"duration\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"certifications\": [],\n",
        "  \"projects\": [\n",
        "    {{\n",
        "      \"title\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"confidence_scores\": {{\n",
        "    \"name\": 0.0,\n",
        "    \"email\": 0.0,\n",
        "    \"phone\": 0.0,\n",
        "    \"linkedin\": 0.0,\n",
        "    \"skills\": 0.0,\n",
        "    \"education\": 0.0,\n",
        "    \"experience\": 0.0,\n",
        "    \"certifications\": 0.0,\n",
        "    \"projects\": 0.0\n",
        "  }}\n",
        "}}\n",
        "\n",
        "Text to extract from:\n",
        "\\\"\\\"\\\"\n",
        "{pdf_text}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "# Call Together API\n",
        "response = requests.post(\n",
        "    \"https://api.together.xyz/v1/chat/completions\",\n",
        "    headers={\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    },\n",
        "    json={\n",
        "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in reading resumes.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"temperature\": 0.1,\n",
        "        \"top_p\": 0.9,\n",
        "        \"max_tokens\": 2048,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Parse the output\n",
        "output = response.json()\n",
        "\n",
        "# Print the full response\n",
        "print(json.dumps(output, indent=2))\n",
        "\n",
        "# Print just the result\n",
        "print(\"\\n\\nResult:\\n\")\n",
        "print(output['choices'][0]['message']['content'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVgk9-Z7mBlU"
      },
      "outputs": [],
      "source": [
        "raw_output = output['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlU7qVcdmXn8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Convert string to a Python dictionary\n",
        "parsed_output = json.loads(raw_output)\n",
        "\n",
        "# Post-process the output to replace string \"null\" with actual None (null in JSON)\n",
        "def clean_json_output(parsed_output):\n",
        "    for key, value in parsed_output.items():\n",
        "        if isinstance(value, dict):\n",
        "            parsed_output[key] = clean_json_output(value)  # Recurse if dictionary\n",
        "        elif isinstance(value, list):\n",
        "            for i in range(len(value)):\n",
        "                if isinstance(value[i], dict):\n",
        "                    value[i] = clean_json_output(value[i])  # Recurse if dictionary inside list\n",
        "                elif value[i] == \"null\":\n",
        "                    value[i] = None  # Replace \"null\" string with actual null (None in Python)\n",
        "        elif value == \"null\":\n",
        "            parsed_output[key] = None  # Replace \"null\" string with actual null (None in Python)\n",
        "    return parsed_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QexvUyUqqJ3N",
        "outputId": "0410f6aa-6be8-40a2-9c2e-46aa4265e1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\": \"SATHISH KUMAR\",\n",
            "  \"email\": \"2310sathishkumarsk@gmail.com\",\n",
            "  \"phone\": \"+91 8825743005\",\n",
            "  \"linkedin\": null,\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"NumPy\",\n",
            "    \"Pandas\",\n",
            "    \"SQL\",\n",
            "    \"MySQL\",\n",
            "    \"Machine Learning\",\n",
            "    \"PyTorch\",\n",
            "    \"Scikit-learn\",\n",
            "    \"Power BI\",\n",
            "    \"Data Analysis\",\n",
            "    \"Natural Language Processing(NLP)\",\n",
            "    \"Data Preprocessing\",\n",
            "    \"Feature Engineering\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Bachelor of Business Administration\",\n",
            "      \"institution\": \"Vidyasagar College of Arts and Science Udumalpet, India\",\n",
            "      \"year\": \"2019 \\u2013 2022\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"Advanced Programming Professional & Master Data Science\",\n",
            "      \"institution\": \"IIT-M GUVI Chennai, India\",\n",
            "      \"year\": \"2023 \\u2013 2024\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": null,\n",
            "      \"title\": \"Data Science Specialist Intern\",\n",
            "      \"duration\": null,\n",
            "      \"description\": \"Eager to contribute to GUVI\\u2019s mission of accessible vernacular tech learning.\"\n",
            "    }\n",
            "  ],\n",
            "  \"certifications\": [\n",
            "    \"Python for Data Science - IBM\",\n",
            "    \"Data Analytics Essentials - CISCO\",\n",
            "    \"Microsoft Power BI - Guvi\"\n",
            "  ],\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"title\": \"Telecom Churn Prediction and Analysis\",\n",
            "      \"description\": \"Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention. Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention efforts. Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on Render for real-time predictions. Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Loan Approval Predictor\",\n",
            "      \"description\": \"Developed a machine learning model to predict loan approval, optimizing the lending decision-making process. Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model evaluation. Analyzed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable, and trained an XGBoost model, achieving 99% accuracy.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"British Airways Data Science Job Simulation\",\n",
            "      \"description\": \"Scraped customer review data from the British Airways website and analyzed sentiment using SentimentIntensityAnalyzer, visualizing key trends with word clouds. Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after hyperparameter tuning. Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence booking decisions. Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\"\n",
            "    }\n",
            "  ],\n",
            "  \"confidence_scores\": {\n",
            "    \"name\": 1.0,\n",
            "    \"email\": 1.0,\n",
            "    \"phone\": 1.0,\n",
            "    \"linkedin\": 0.0,\n",
            "    \"skills\": 1.0,\n",
            "    \"education\": 1.0,\n",
            "    \"experience\": 0.5,\n",
            "    \"certifications\": 1.0,\n",
            "    \"projects\": 1.0\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Clean the parsed output\n",
        "cleaned_output = clean_json_output(parsed_output)\n",
        "\n",
        "# Print cleaned output\n",
        "print(json.dumps(cleaned_output, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QHCKDNzslh9"
      },
      "source": [
        "## focus Image based pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS3WmFBAst-M",
        "outputId": "f8c8e878-bc9a-43ee-e3cc-63c1bcbabc1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "Successfully installed pdf2image-1.17.0 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract pdf2image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V36ZzFGwpq8",
        "outputId": "ec747588-47de-4254-ee92-9453a7423eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.7 [186 kB]\n",
            "Fetched 186 kB in 0s (891 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126101 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.7_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bIkVZAEqRC0",
        "outputId": "a450bcba-7d0c-455d-f3cb-b3842faac97d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SATHISH KUMAR\n",
            "\n",
            "Data Scientist\n",
            "\n",
            "& 2310sathishkumarsk@gmail.com &, +91 8825743005 @ Tiruppur, India ff LinkedIn €) Github\n",
            "\n",
            "PROFILE\n",
            "\n",
            "Motivated and detail-oriented Data Science enthusiast with a solid foundation in Python, SQL, Machine Learning, and\n",
            "Deep Learning. Trained under GUVI's IIT-M incubated program and completed real-world projects focusing on data-\n",
            "driven decision-making. Eager to contribute to GUVI’s mission of accessible vernacular tech learning as a Data Science\n",
            "Specialist Intern.\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Python | NumPy | Pandas | SQL | MySQL | Machine Learning | PyTorch | Scikit-learn | Power BI |\n",
            "Data Analysis | Natural Language Processing (NLP) | Data Preprocessing | Feature Engineering\n",
            "\n",
            "PRACTICAL EXPERIENCE\n",
            "\n",
            "Telecom Churn Prediction and Analysis &\n",
            "\n",
            "Key Skills: Python, Machine Learning, Power BI, EDA, Data Visualization\n",
            "\n",
            "e Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention.\n",
            "\n",
            "+ Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention\n",
            "efforts.\n",
            "\n",
            "e Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on\n",
            "Render for real-time predictions.\n",
            "\n",
            "e Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\n",
            "\n",
            "Loan Approval Predictor ?\n",
            "\n",
            "Key Skills: Python, Machine Learning, EDA, XGBoost, Data Preprocessing, Model Evaluation\n",
            "\n",
            "e Developed a machine learning model to predict loan approval, optimizing the lending decision-making process.\n",
            "\n",
            "e Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model\n",
            "evaluation.\n",
            "\n",
            "+ Analysed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable,\n",
            "and trained an XGBoost model, achieving 99% accuracy.\n",
            "\n",
            "e Provided a scalable, data-driven solution for loan processing, improving decision-making efficiency.\n",
            "\n",
            "British Airways Data Science Job Simulation 2\n",
            "\n",
            "Data Scraping, Sentiment Analysis, Random Forest, Feature Engineering, Python\n",
            "\n",
            "« Scraped customer review data from the British Airways website and analyzed sentiment using\n",
            "SentimentIntensityAnalyzer, visualizing key trends with word clouds,\n",
            "\n",
            "¢ Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after\n",
            "hyperparameter tuning.\n",
            "\n",
            "Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence\n",
            "booking decisions.\n",
            "\n",
            "¢ Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Advanced Programming Professional & Master Data Science 2023 -— 2024\n",
            "IIT-M GUVI Chennai, India\n",
            "Bachelor of Business Administration 2019 — 2022\n",
            "Vidyasagar College of Arts and Science Udumalpet, India\n",
            "CERTIFICATES\n",
            "\n",
            "¢ Python for Data Science - IBM &\n",
            "¢ Data Analytics Essentials - CISCO @\n",
            "* Microsoft Power BI - Guvi #\n",
            "\f\n"
          ]
        }
      ],
      "source": [
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# Path to your PDF file\n",
        "pdf_path = '/content/r01.pdf'\n",
        "\n",
        "# Convert PDF to images\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# OCR the images and extract text\n",
        "extracted_text = \"\"\n",
        "for img in images:\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    extracted_text += text\n",
        "\n",
        "print(extracted_text)  # Display extracted text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HIwNcBW-fKkP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_ocr(text):\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)  # Remove non-ASCII\n",
        "    text = re.sub(r\"[&*@#€¢•¶]+\", \"\", text)     # Remove common OCR junk\n",
        "    #text = re.sub(r\"\\s{2,}\", \" \", text)         # Replace multiple spaces with one\n",
        "    return text.strip()\n",
        "\n",
        "cleaned_text = preprocess_ocr(extracted_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drZxIfOFfTMd",
        "outputId": "19b65dd6-1aa5-4890-b7e1-f55b98dd97dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SATHISH KUMAR\n",
            "\n",
            "Data Scientist\n",
            "\n",
            " 2310sathishkumarskgmail.com , +91 8825743005  Tiruppur, India ff LinkedIn ) Github\n",
            "\n",
            "PROFILE\n",
            "\n",
            "Motivated and detail-oriented Data Science enthusiast with a solid foundation in Python, SQL, Machine Learning, and\n",
            "Deep Learning. Trained under GUVI's IIT-M incubated program and completed real-world projects focusing on data-\n",
            "driven decision-making. Eager to contribute to GUVIs mission of accessible vernacular tech learning as a Data Science\n",
            "Specialist Intern.\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Python | NumPy | Pandas | SQL | MySQL | Machine Learning | PyTorch | Scikit-learn | Power BI |\n",
            "Data Analysis | Natural Language Processing (NLP) | Data Preprocessing | Feature Engineering\n",
            "\n",
            "PRACTICAL EXPERIENCE\n",
            "\n",
            "Telecom Churn Prediction and Analysis \n",
            "\n",
            "Key Skills: Python, Machine Learning, Power BI, EDA, Data Visualization\n",
            "\n",
            "e Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention.\n",
            "\n",
            "+ Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention\n",
            "efforts.\n",
            "\n",
            "e Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on\n",
            "Render for real-time predictions.\n",
            "\n",
            "e Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\n",
            "\n",
            "Loan Approval Predictor ?\n",
            "\n",
            "Key Skills: Python, Machine Learning, EDA, XGBoost, Data Preprocessing, Model Evaluation\n",
            "\n",
            "e Developed a machine learning model to predict loan approval, optimizing the lending decision-making process.\n",
            "\n",
            "e Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model\n",
            "evaluation.\n",
            "\n",
            "+ Analysed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable,\n",
            "and trained an XGBoost model, achieving 99% accuracy.\n",
            "\n",
            "e Provided a scalable, data-driven solution for loan processing, improving decision-making efficiency.\n",
            "\n",
            "British Airways Data Science Job Simulation 2\n",
            "\n",
            "Data Scraping, Sentiment Analysis, Random Forest, Feature Engineering, Python\n",
            "\n",
            " Scraped customer review data from the British Airways website and analyzed sentiment using\n",
            "SentimentIntensityAnalyzer, visualizing key trends with word clouds,\n",
            "\n",
            " Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after\n",
            "hyperparameter tuning.\n",
            "\n",
            "Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence\n",
            "booking decisions.\n",
            "\n",
            " Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "Advanced Programming Professional  Master Data Science 2023 - 2024\n",
            "IIT-M GUVI Chennai, India\n",
            "Bachelor of Business Administration 2019  2022\n",
            "Vidyasagar College of Arts and Science Udumalpet, India\n",
            "CERTIFICATES\n",
            "\n",
            " Python for Data Science - IBM \n",
            " Data Analytics Essentials - CISCO \n",
            " Microsoft Power BI - Guvi\n"
          ]
        }
      ],
      "source": [
        "print(cleaned_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXle4hZfecuV",
        "outputId": "35d7fbba-c4fc-4d01-bd55-b5d14b98e0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"ns2pmGo-3NKUce-937ecaf0d9d1e829\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1745929638,\n",
            "  \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
            "  \"prompt\": [],\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"seed\": 3843311838032930000,\n",
            "      \"logprobs\": null,\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \" {\\n  \\\"name\\\": \\\"SATHISH KUMAR\\\",\\n  \\\"email\\\": \\\"2310sathishkumarskgmail.com\\\",\\n  \\\"phone\\\": \\\"+91 8825743005\\\",\\n  \\\"linkedin\\\": null,\\n  \\\"skills\\\": [\\\"Python\\\", \\\"NumPy\\\", \\\"Pandas\\\", \\\"SQL\\\", \\\"MySQL\\\", \\\"Machine Learning\\\", \\\"PyTorch\\\", \\\"Scikit-learn\\\", \\\"Power BI\\\", \\\"Data Analysis\\\", \\\"Natural Language Processing (NLP)\\\", \\\"Data Preprocessing\\\", \\\"Feature Engineering\\\"],\\n  \\\"education\\\": [\\n    {\\n      \\\"degree\\\": \\\"Advanced Programming Professional Master Data Science\\\",\\n      \\\"institution\\\": \\\"IIT-M GUVI Chennai, India\\\",\\n      \\\"year\\\": \\\"2023 - 2024\\\"\\n    },\\n    {\\n      \\\"degree\\\": \\\"Bachelor of Business Administration\\\",\\n      \\\"institution\\\": \\\"Vidyasagar College of Arts and Science Udumalpet, India\\\",\\n      \\\"year\\\": \\\"2019  2022\\\"\\n    }\\n  ],\\n  \\\"experience\\\": [\\n    {\\n      \\\"company\\\": null,\\n      \\\"title\\\": \\\"Data Science Specialist Intern\\\",\\n      \\\"duration\\\": null,\\n      \\\"description\\\": \\\"Eager to contribute to GUVIs mission of accessible vernacular tech learning.\\\"\\n    }\\n  ],\\n  \\\"certifications\\\": [\\n    \\\"Python for Data Science - IBM\\\",\\n    \\\"Data Analytics Essentials - CISCO\\\",\\n    \\\"Microsoft Power BI - Guvi\\\"\\n  ],\\n  \\\"projects\\\": [\\n    {\\n      \\\"title\\\": \\\"Telecom Churn Prediction and Analysis\\\",\\n      \\\"description\\\": \\\"Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention. Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention efforts. Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on Render for real-time predictions. Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\\\"\\n    },\\n    {\\n      \\\"title\\\": \\\"Loan Approval Predictor\\\",\\n      \\\"description\\\": \\\"Developed a machine learning model to predict loan approval, optimizing the lending decision-making process. Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model evaluation. Analyzed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable, and trained an XGBoost model, achieving 99% accuracy. Provided a scalable, data-driven solution for loan processing, improving decision-making efficiency.\\\"\\n    },\\n    {\\n      \\\"title\\\": \\\"British Airways Data Science Job Simulation 2\\\",\\n      \\\"description\\\": \\\"Scraped customer review data from the British Airways website and analyzed sentiment using SentimentIntensityAnalyzer, visualizing key trends with word clouds. Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after hyperparameter tuning. Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence booking decisions. Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\\\"\\n    }\\n  ],\\n  \\\"confidence_scores\\\": {\\n    \\\"name\\\": 1.0,\\n    \\\"email\\\": 1.0,\\n    \\\"phone\\\": 1.0,\\n    \\\"linkedin\\\": 0.0,\\n    \\\"skills\\\": 1.0,\\n    \\\"education\\\": 1.0,\\n    \\\"experience\\\": 0.5,\\n    \\\"certifications\\\": 1.0,\\n    \\\"projects\\\": 1.0\\n  }\\n}\",\n",
            "        \"tool_calls\": []\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 1484,\n",
            "    \"completion_tokens\": 899,\n",
            "    \"total_tokens\": 2383\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "Result:\n",
            "\n",
            " {\n",
            "  \"name\": \"SATHISH KUMAR\",\n",
            "  \"email\": \"2310sathishkumarskgmail.com\",\n",
            "  \"phone\": \"+91 8825743005\",\n",
            "  \"linkedin\": null,\n",
            "  \"skills\": [\"Python\", \"NumPy\", \"Pandas\", \"SQL\", \"MySQL\", \"Machine Learning\", \"PyTorch\", \"Scikit-learn\", \"Power BI\", \"Data Analysis\", \"Natural Language Processing (NLP)\", \"Data Preprocessing\", \"Feature Engineering\"],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Advanced Programming Professional Master Data Science\",\n",
            "      \"institution\": \"IIT-M GUVI Chennai, India\",\n",
            "      \"year\": \"2023 - 2024\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"Bachelor of Business Administration\",\n",
            "      \"institution\": \"Vidyasagar College of Arts and Science Udumalpet, India\",\n",
            "      \"year\": \"2019  2022\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": null,\n",
            "      \"title\": \"Data Science Specialist Intern\",\n",
            "      \"duration\": null,\n",
            "      \"description\": \"Eager to contribute to GUVIs mission of accessible vernacular tech learning.\"\n",
            "    }\n",
            "  ],\n",
            "  \"certifications\": [\n",
            "    \"Python for Data Science - IBM\",\n",
            "    \"Data Analytics Essentials - CISCO\",\n",
            "    \"Microsoft Power BI - Guvi\"\n",
            "  ],\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"title\": \"Telecom Churn Prediction and Analysis\",\n",
            "      \"description\": \"Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention. Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention efforts. Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on Render for real-time predictions. Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Loan Approval Predictor\",\n",
            "      \"description\": \"Developed a machine learning model to predict loan approval, optimizing the lending decision-making process. Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model evaluation. Analyzed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable, and trained an XGBoost model, achieving 99% accuracy. Provided a scalable, data-driven solution for loan processing, improving decision-making efficiency.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"British Airways Data Science Job Simulation 2\",\n",
            "      \"description\": \"Scraped customer review data from the British Airways website and analyzed sentiment using SentimentIntensityAnalyzer, visualizing key trends with word clouds. Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after hyperparameter tuning. Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence booking decisions. Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\"\n",
            "    }\n",
            "  ],\n",
            "  \"confidence_scores\": {\n",
            "    \"name\": 1.0,\n",
            "    \"email\": 1.0,\n",
            "    \"phone\": 1.0,\n",
            "    \"linkedin\": 0.0,\n",
            "    \"skills\": 1.0,\n",
            "    \"education\": 1.0,\n",
            "    \"experience\": 0.5,\n",
            "    \"certifications\": 1.0,\n",
            "    \"projects\": 1.0\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pdfplumber\n",
        "\n",
        "\n",
        "# Define prompt\n",
        "prompt = f\"\"\"\n",
        "You are an expert resume parser.\n",
        "\n",
        "Task:\n",
        "Parse the following resume content and extract structured fields. Return the result ONLY in the following strict JSON format:\n",
        "\n",
        "Instructions:\n",
        "- Do not guess. If a field is not explicitly present in the text, set its value to the JSON null value (without quotes).\n",
        "- Read the ENTIRE content carefully, especially the profile/summary and projects section, to extract all relevant skills.\n",
        "- Add skills from projects or summary sections **only if they are not already included** in the skills list.\n",
        "- LinkedIn: Only extract a LinkedIn URL if it is a valid personal LinkedIn profile (e.g., starts with \"https://linkedin.com/in/username\"). If it's just the word \"LinkedIn\", a logo, or a general link (e.g., \"linkedin.com\"), set the field to null.\n",
        "- Work Experience vs. Projects:\n",
        "  - Treat as **work experience** only if BOTH a valid company name and a clear duration (e.g., \"Jan 2020 – Mar 2022\") are present.\n",
        "  - If any of the following are **missing** — company name, duration, or job title — classify it as a **project**.\n",
        "  - Terms like \"Project\", \"Capstone\", \"Intern Project\", \"Practical Experience\", or job simulation **should be treated as projects**, NOT experience.\n",
        "- Extract project title and description from such entries and move them to the \"projects\" section.\n",
        "- Normalize all dates to \"MMM YYYY\" format where possible (e.g., \"Jan 2020\").\n",
        "- Include a confidence score (0.0–1.0) for each field in the `confidence_scores` section.\n",
        "- Return all results ONLY in this strict JSON format:\n",
        "\n",
        "{{\n",
        "  \"name\": \"\",\n",
        "  \"email\": \"\",\n",
        "  \"phone\": \"\",\n",
        "  \"linkedin\": \"\",\n",
        "  \"skills\": [],\n",
        "  \"education\": [\n",
        "    {{\n",
        "      \"degree\": \"\",\n",
        "      \"institution\": \"\",\n",
        "      \"year\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"experience\": [\n",
        "    {{\n",
        "      \"company\": \"\",\n",
        "      \"title\": \"\",\n",
        "      \"duration\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"certifications\": [],\n",
        "  \"projects\": [\n",
        "    {{\n",
        "      \"title\": \"\",\n",
        "      \"description\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"confidence_scores\": {{\n",
        "    \"name\": 0.0,\n",
        "    \"email\": 0.0,\n",
        "    \"phone\": 0.0,\n",
        "    \"linkedin\": 0.0,\n",
        "    \"skills\": 0.0,\n",
        "    \"education\": 0.0,\n",
        "    \"experience\": 0.0,\n",
        "    \"certifications\": 0.0,\n",
        "    \"projects\": 0.0\n",
        "  }}\n",
        "}}\n",
        "\n",
        "Text to extract from:\n",
        "\\\"\\\"\\\"\n",
        "{cleaned_text}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "# Call Together API\n",
        "response = requests.post(\n",
        "    \"https://api.together.xyz/v1/chat/completions\",\n",
        "    headers={\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    },\n",
        "    json={\n",
        "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in reading resumes.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"temperature\": 0.1,\n",
        "        \"top_p\": 0.9,\n",
        "        \"max_tokens\": 2048,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Parse the output\n",
        "output = response.json()\n",
        "\n",
        "# Print the full response\n",
        "print(json.dumps(output, indent=2))\n",
        "\n",
        "# Print just the result\n",
        "print(\"\\n\\nResult:\\n\")\n",
        "print(output['choices'][0]['message']['content'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Llz9azL0gh_9"
      },
      "outputs": [],
      "source": [
        "raw_output = output['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UXh8-12tg5b-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Convert string to a Python dictionary\n",
        "parsed_output = json.loads(raw_output)\n",
        "\n",
        "# Post-process the output to replace string \"null\" with actual None (null in JSON)\n",
        "def clean_json_output(parsed_output):\n",
        "    for key, value in parsed_output.items():\n",
        "        if isinstance(value, dict):\n",
        "            parsed_output[key] = clean_json_output(value)  # Recurse if dictionary\n",
        "        elif isinstance(value, list):\n",
        "            for i in range(len(value)):\n",
        "                if isinstance(value[i], dict):\n",
        "                    value[i] = clean_json_output(value[i])  # Recurse if dictionary inside list\n",
        "                elif value[i] == \"null\":\n",
        "                    value[i] = None  # Replace \"null\" string with actual null (None in Python)\n",
        "        elif value == \"null\":\n",
        "            parsed_output[key] = None  # Replace \"null\" string with actual null (None in Python)\n",
        "    return parsed_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTBncfuYg_Jl",
        "outputId": "6f03c754-636a-40ac-9dbb-a1bb00b01322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\": \"SATHISH KUMAR\",\n",
            "  \"email\": \"2310sathishkumarskgmail.com\",\n",
            "  \"phone\": \"+91 8825743005\",\n",
            "  \"linkedin\": null,\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"NumPy\",\n",
            "    \"Pandas\",\n",
            "    \"SQL\",\n",
            "    \"MySQL\",\n",
            "    \"Machine Learning\",\n",
            "    \"PyTorch\",\n",
            "    \"Scikit-learn\",\n",
            "    \"Power BI\",\n",
            "    \"Data Analysis\",\n",
            "    \"Natural Language Processing (NLP)\",\n",
            "    \"Data Preprocessing\",\n",
            "    \"Feature Engineering\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"degree\": \"Advanced Programming Professional Master Data Science\",\n",
            "      \"institution\": \"IIT-M GUVI Chennai, India\",\n",
            "      \"year\": \"2023 - 2024\"\n",
            "    },\n",
            "    {\n",
            "      \"degree\": \"Bachelor of Business Administration\",\n",
            "      \"institution\": \"Vidyasagar College of Arts and Science Udumalpet, India\",\n",
            "      \"year\": \"2019  2022\"\n",
            "    }\n",
            "  ],\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": null,\n",
            "      \"title\": \"Data Science Specialist Intern\",\n",
            "      \"duration\": null,\n",
            "      \"description\": \"Eager to contribute to GUVIs mission of accessible vernacular tech learning.\"\n",
            "    }\n",
            "  ],\n",
            "  \"certifications\": [\n",
            "    \"Python for Data Science - IBM\",\n",
            "    \"Data Analytics Essentials - CISCO\",\n",
            "    \"Microsoft Power BI - Guvi\"\n",
            "  ],\n",
            "  \"projects\": [\n",
            "    {\n",
            "      \"title\": \"Telecom Churn Prediction and Analysis\",\n",
            "      \"description\": \"Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention. Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention efforts. Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on Render for real-time predictions. Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Loan Approval Predictor\",\n",
            "      \"description\": \"Developed a machine learning model to predict loan approval, optimizing the lending decision-making process. Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model evaluation. Analyzed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable, and trained an XGBoost model, achieving 99% accuracy. Provided a scalable, data-driven solution for loan processing, improving decision-making efficiency.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"British Airways Data Science Job Simulation 2\",\n",
            "      \"description\": \"Scraped customer review data from the British Airways website and analyzed sentiment using SentimentIntensityAnalyzer, visualizing key trends with word clouds. Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after hyperparameter tuning. Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence booking decisions. Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.\"\n",
            "    }\n",
            "  ],\n",
            "  \"confidence_scores\": {\n",
            "    \"name\": 1.0,\n",
            "    \"email\": 1.0,\n",
            "    \"phone\": 1.0,\n",
            "    \"linkedin\": 0.0,\n",
            "    \"skills\": 1.0,\n",
            "    \"education\": 1.0,\n",
            "    \"experience\": 0.5,\n",
            "    \"certifications\": 1.0,\n",
            "    \"projects\": 1.0\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Clean the parsed output\n",
        "cleaned_output = clean_json_output(parsed_output)\n",
        "\n",
        "# Print cleaned output\n",
        "print(json.dumps(cleaned_output, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Lkl2-_dFeiSd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def fix_email(email):\n",
        "    if email and \"@\" not in email:\n",
        "        # Try inserting '@' before 'gmail' or 'yahoo' etc.\n",
        "        match = re.search(r\"(\\w+)(gmail|yahoo|outlook|protonmail|hotmail)\\.com\", email)\n",
        "        if match:\n",
        "            corrected = match.group(1) + \"@\" + match.group(2) + \".com\"\n",
        "            return corrected\n",
        "    return email\n",
        "\n",
        "cleaned_output[\"email\"] = fix_email(cleaned_output[\"email\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZSTb1IYhHYl",
        "outputId": "2820d4b6-bee0-4e02-9e02-165a700304d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'SATHISH KUMAR',\n",
              " 'email': '2310sathishkumarsk@gmail.com',\n",
              " 'phone': '+91 8825743005',\n",
              " 'linkedin': None,\n",
              " 'skills': ['Python',\n",
              "  'NumPy',\n",
              "  'Pandas',\n",
              "  'SQL',\n",
              "  'MySQL',\n",
              "  'Machine Learning',\n",
              "  'PyTorch',\n",
              "  'Scikit-learn',\n",
              "  'Power BI',\n",
              "  'Data Analysis',\n",
              "  'Natural Language Processing (NLP)',\n",
              "  'Data Preprocessing',\n",
              "  'Feature Engineering'],\n",
              " 'education': [{'degree': 'Advanced Programming Professional Master Data Science',\n",
              "   'institution': 'IIT-M GUVI Chennai, India',\n",
              "   'year': '2023 - 2024'},\n",
              "  {'degree': 'Bachelor of Business Administration',\n",
              "   'institution': 'Vidyasagar College of Arts and Science Udumalpet, India',\n",
              "   'year': '2019  2022'}],\n",
              " 'experience': [{'company': None,\n",
              "   'title': 'Data Science Specialist Intern',\n",
              "   'duration': None,\n",
              "   'description': 'Eager to contribute to GUVIs mission of accessible vernacular tech learning.'}],\n",
              " 'certifications': ['Python for Data Science - IBM',\n",
              "  'Data Analytics Essentials - CISCO',\n",
              "  'Microsoft Power BI - Guvi'],\n",
              " 'projects': [{'title': 'Telecom Churn Prediction and Analysis',\n",
              "   'description': 'Developed a predictive model to identify telecom customers at risk of churn, allowing early intervention. Performed EDA on 6,418 customer records (27% churn rate) to uncover key churn drivers and optimize retention efforts. Trained and evaluated a Gradient Boosting Classifier, achieving 85% accuracy, and implemented a Flask web app on Render for real-time predictions. Designed and integrated a Power BI dashboard, delivering interactive insights to support data-driven decision-making.'},\n",
              "  {'title': 'Loan Approval Predictor',\n",
              "   'description': 'Developed a machine learning model to predict loan approval, optimizing the lending decision-making process. Enabled financial institutions to assess loan eligibility efficiently using EDA, feature engineering, and model evaluation. Analyzed 4,269 records (13 features), performed EDA and correlation analysis, engineered a unified asset variable, and trained an XGBoost model, achieving 99% accuracy. Provided a scalable, data-driven solution for loan processing, improving decision-making efficiency.'},\n",
              "  {'title': 'British Airways Data Science Job Simulation 2',\n",
              "   'description': 'Scraped customer review data from the British Airways website and analyzed sentiment using SentimentIntensityAnalyzer, visualizing key trends with word clouds. Built a Random Forest model to predict customer purchasing behavior, achieving 85.3% accuracy after hyperparameter tuning. Identified key predictors such as purchase lead time, trip type, and sales channel, which significantly influence booking decisions. Delivered actionable insights that can help airlines personalize marketing strategies and boost sales.'}],\n",
              " 'confidence_scores': {'name': 1.0,\n",
              "  'email': 1.0,\n",
              "  'phone': 1.0,\n",
              "  'linkedin': 0.0,\n",
              "  'skills': 1.0,\n",
              "  'education': 1.0,\n",
              "  'experience': 0.5,\n",
              "  'certifications': 1.0,\n",
              "  'projects': 1.0}}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
